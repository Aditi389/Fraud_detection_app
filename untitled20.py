# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wFxJAyr23phxAH7-uTPuuaYrqK6JW9EX
"""

# app.py

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Standard ML imports
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Imbalanced data fix
from imblearn.over_sampling import SMOTE  # not used here, but leaving it for potential future tweaks
from xgboost import XGBClassifier

# Just disabling that annoying global pyplot warning
# st.set_option('deprecation.showPyplotGlobalUse', False)

st.title("Fraudulent Transaction Detection App")

# --- Upload Section ---
train_file = st.file_uploader("Upload the Training CSV file", type=["csv"])
test_file = st.file_uploader("Upload the Testing CSV file", type=["csv"])

# Once both files are uploaded...
if train_file and test_file:
    df_train = pd.read_csv(train_file)
    df_test = pd.read_csv(test_file)

    st.subheader("A Quick Look at the Data")
    st.write("Training Sample", df_train.head())
    st.write("Testing Sample", df_test.head())

    # Dropping columns we likely won't use — feels like metadata mostly
    junk_cols = ['Unnamed: 0', 'trans_num', 'unix_time', 'first', 'last', 'long', 'lat']
    df_train.drop(columns=junk_cols, inplace=True, errors='ignore')  # 'errors' param avoids crashing
    df_test.drop(columns=junk_cols, inplace=True, errors='ignore')

    # Pulling out the target
    X_train = df_train.drop(columns=['is_fraud'])
    y_train = df_train['is_fraud']

    X_test = df_test.drop(columns=['is_fraud'])
    y_test = df_test['is_fraud']

    # Some datetime feature engineering
    if 'trans_date_trans_time' in X_train.columns:
        for df in [X_train, X_test]:
            df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], errors='coerce')
            df['hour'] = df['trans_date_trans_time'].dt.hour
            df['day'] = df['trans_date_trans_time'].dt.day
            df['month'] = df['trans_date_trans_time'].dt.month
            df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek
            df.drop(columns=['trans_date_trans_time'], inplace=True)

    # Encoding strings into numbers (because models can’t read text)
    label_enc = LabelEncoder()
    cat_features = X_train.select_dtypes(include='object').columns.tolist()

    for col in cat_features:
        combined_vals = pd.concat([X_train[col], X_test[col]])
        label_enc.fit(combined_vals)
        X_train[col] = label_enc.transform(X_train[col])
        X_test[col] = label_enc.transform(X_test[col])

    # Scale numeric features to standard normal — good ol' z-score
    num_features = X_train.select_dtypes(include=np.number).columns.tolist()
    scaler = StandardScaler()
    X_train[num_features] = scaler.fit_transform(X_train[num_features])
    X_test[num_features] = scaler.transform(X_test[num_features])

    # Make sure train and test match up (column-wise)
    X_train, X_test = X_train.align(X_test, join='inner', axis=1)

    st.success("Data looks ready to go!")

    # Let user pick which model to run
    algo = st.radio("Which model should we use?", ("Random Forest", "XGBoost"))

    if st.button("Train & Evaluate"):
        # Kicking off training based on user selection
        if algo == "Random Forest":
            model = RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=42)
        else:
            model = XGBClassifier(n_estimators=300, max_depth=30, learning_rate=0.005)

        # Fit the model
        model.fit(X_train, y_train)

        # Make predictions
        predictions = model.predict(X_test)

        # Confusion Matrix Visualization
        st.subheader("Confusion Matrix")
        fig1, ax1 = plt.subplots()
        cm = confusion_matrix(y_test, predictions)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1)
        st.pyplot(fig1)

        # Classification metrics
        st.subheader("Classification Report")
        st.text(classification_report(y_test, predictions))

        acc = accuracy_score(y_test, predictions)
        st.success(f"Accuracy is: {acc * 100:.2f}%")

        # Feature Importance
        st.subheader("Feature Importance Breakdown")
        feat_imp = pd.DataFrame({
            'Feature': X_train.columns,
            'Importance': model.feature_importances_
        }).sort_values(by='Importance', ascending=False)

        st.dataframe(feat_imp)

        # Barplot for top features
        fig2, ax2 = plt.subplots()
        sns.barplot(x='Importance', y='Feature', data=feat_imp.head(10), ax=ax2)
        st.pyplot(fig2)

        # Attach predictions to test set and extract only fraudulent ones
        df_test['predicted_is_fraud'] = predictions
        flagged = df_test[df_test['predicted_is_fraud'] == 1]

        st.subheader("Flagged Transactions (Predicted Fraud)")
        st.write(flagged.head())

        st.download_button(
            "Download the Predicted Fraud Cases",
            data=flagged.to_csv(index=False).encode('utf-8'),
            file_name='predicted_fraud.csv',
            mime='text/csv'
        )